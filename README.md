# CreateRL
#### Classic Reinforcement Learning algorithms

The goal of this project is to implement RL algorithms. There already exists a wealth of different implementations of these algorithms. However, it isn't easy to see the sometimes nuanced differences in code- and algorithmic design when comparing different code bases. Thus, I am trying to make the implementations in this rep easy to understand and the algorithm hopefully more effortless for you to compare.

It also includes a simple environment, where the task is for a single player to find a randomly spawned treasure on a x by y grid map.


Name | Paper | Notes 
---|---|---
---|_Q-learning Methods_ |---
DQN | [Playing Atari with Deep Reinforcement Learning](https://www.cs.toronto.edu/~vmnih/docs/dqn.pdf)  | 
Double DQN (DDQN)|[Deep Reinforcement Learning with Double Q-learning](https://arxiv.org/abs/1509.06461) | 
Prioritized Experience Replay (PER) | [Prioritized Experience Replay](https://arxiv.org/abs/1511.05952) | 
---|_Policy Gradient Methods_ |---
(Vanilla) Policy Gradient | [High-Dimensional Continuous Control Using Generalized Advantage Estimation](https://arxiv.org/abs/1506.02438) |
---|_Other Methods_|---
Augmented Random Search | [Simple random search provides a competitive approach to reinforcement learning](https://arxiv.org/abs/1803.07055) | Next